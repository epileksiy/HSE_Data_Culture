{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"center\" src=\"https://raw.githubusercontent.com/FUlyankin/Parsers/master/images%20/cats.jpg\" height=\"1200\" width=\"1200\"> \n",
    "\n",
    "# Мини-домашка 4: регрессия\n",
    "\n",
    "На семинаре мы пытались спрогнозировать сколько лайков поставит студент первого курса в вышкинский паблик с мемасами. Наша итоговая модель получилась довольно хлипкой. Хотелось бы улучшить её. В этом домашнем задании именно этим вы и займётесь. По ходу кода ниже будет довольно много пустых строк. Нужнозаполнить их своим кодом. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd               # уже знакомый вам пакет для работы с таблицами\n",
    "import numpy as np                # смутно знакомый вам пакет для работы с матрицами\n",
    "import matplotlib.pyplot as plt   # уже смутно знакомый вам пакет для картинок :3\n",
    "import seaborn as sns             # ещё один пакет для картинок \n",
    "plt.style.use('ggplot')     # правильный (очень красивый) стиль у графиков\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Подготовка \n",
    "\n",
    "Ровно также как мы это делали на семинаре, подгружаем данные и делаем их предобработку. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>likes_memes</th>\n",
       "      <th>uid</th>\n",
       "      <th>male_dummy</th>\n",
       "      <th>facebook_dummy</th>\n",
       "      <th>instagram_dummy</th>\n",
       "      <th>skype_dummy</th>\n",
       "      <th>twitter_dummy</th>\n",
       "      <th>...</th>\n",
       "      <th>photo_repost_cnt</th>\n",
       "      <th>photo_repost_max</th>\n",
       "      <th>photo_repost_mean</th>\n",
       "      <th>photo_repost_median</th>\n",
       "      <th>photo_text_len_cnt</th>\n",
       "      <th>photo_ava_change_cnt</th>\n",
       "      <th>photo_text_url_len_cnt</th>\n",
       "      <th>friends_from_course_cnt</th>\n",
       "      <th>friends_mail_from_course_pct</th>\n",
       "      <th>ln_likes_memes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Россия</td>\n",
       "      <td>Артём</td>\n",
       "      <td>Еркин</td>\n",
       "      <td>0</td>\n",
       "      <td>181029517</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.833213</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Россия</td>\n",
       "      <td>Армен</td>\n",
       "      <td>Хачатрян</td>\n",
       "      <td>15</td>\n",
       "      <td>73703994</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.871201</td>\n",
       "      <td>0.531915</td>\n",
       "      <td>2.708050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Россия</td>\n",
       "      <td>Abbos</td>\n",
       "      <td>Akhmedov</td>\n",
       "      <td>11</td>\n",
       "      <td>467673028</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.295837</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.397895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Россия</td>\n",
       "      <td>Адам</td>\n",
       "      <td>Триандафилиди</td>\n",
       "      <td>0</td>\n",
       "      <td>144910934</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.430817</td>\n",
       "      <td>0.518072</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Казахстан</td>\n",
       "      <td>Айжан</td>\n",
       "      <td>Саят</td>\n",
       "      <td>9</td>\n",
       "      <td>166045266</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.401197</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>2.197225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     country first_name      last_name  likes_memes        uid  male_dummy  \\\n",
       "0     Россия      Артём          Еркин            0  181029517           1   \n",
       "1     Россия      Армен       Хачатрян           15   73703994           1   \n",
       "2     Россия      Abbos       Akhmedov           11  467673028           1   \n",
       "3     Россия       Адам  Триандафилиди            0  144910934           1   \n",
       "4  Казахстан      Айжан           Саят            9  166045266           0   \n",
       "\n",
       "   facebook_dummy  instagram_dummy  skype_dummy  twitter_dummy  ...  \\\n",
       "0               0                0            0              0  ...   \n",
       "1               0                1            0              0  ...   \n",
       "2               0                0            0              0  ...   \n",
       "3               0                1            1              0  ...   \n",
       "4               0                0            0              0  ...   \n",
       "\n",
       "   photo_repost_cnt  photo_repost_max  photo_repost_mean  photo_repost_median  \\\n",
       "0          0.000000               0.0           0.000000                  0.0   \n",
       "1          1.609438               1.0           0.571429                  1.0   \n",
       "2          0.000000               0.0           0.000000                  0.0   \n",
       "3          0.000000               0.0           0.000000                  0.0   \n",
       "4          0.000000               0.0           0.000000                  0.0   \n",
       "\n",
       "   photo_text_len_cnt  photo_ava_change_cnt  photo_text_url_len_cnt  \\\n",
       "0                 0.0                   0.0                     0.0   \n",
       "1                 0.0                   0.0                     0.0   \n",
       "2                 0.0                   0.0                     0.0   \n",
       "3                 0.0                   0.0                     0.0   \n",
       "4                 0.0                   0.0                     0.0   \n",
       "\n",
       "   friends_from_course_cnt  friends_mail_from_course_pct  ln_likes_memes  \n",
       "0                 2.833213                      0.375000       -0.000000  \n",
       "1                 3.871201                      0.531915        2.708050  \n",
       "2                 3.295837                      0.500000        2.397895  \n",
       "3                 4.430817                      0.518072       -0.000000  \n",
       "4                 3.401197                      0.344828        2.197225  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/vk_main.csv', sep='\\t')   # подгружаем датасет\n",
    "\n",
    "# варим таргет в виде логарифма \n",
    "df['ln_likes_memes'] = df['likes_memes'].apply(lambda w: np.log(w) if w > 0 else -np.log(-1*w + 1))\n",
    "\n",
    "# выбрасываем из выборки все переменные, в которых слишком много пропусков\n",
    "isnull = df.isnull().sum()\n",
    "df = df[isnull[isnull <= 56].index]\n",
    "\n",
    "# Выборка с переменными-счётчиками\n",
    "variables_cnt = [item for item in df.columns if item[-3:] == 'cnt']\n",
    "\n",
    "# Оставляем только информативные переменные (картинки можно посмотреть в семинарской тетрадке)\n",
    "variables_cnt = [item for item in variables_cnt if len(df[item].unique()) > 10]\n",
    "\n",
    "# логарифмируем счётчики\n",
    "df[variables_cnt] = df[variables_cnt].apply(lambda w: np.log(w + 1))\n",
    "\n",
    "# отбираем дамми - переменные \n",
    "variables_dummy = [item for item in df.columns if item[-5:] == 'dummy']\n",
    "\n",
    "# средние, медианы и максимумы\n",
    "variables_mean = [item for item in df.columns if item[-4:] == 'mean']\n",
    "variables_median = [item for item in df.columns if item[-6:] == 'median']\n",
    "variables_max = [item for item in df.columns if item[-3:] == 'max']\n",
    "\n",
    "# все полезные переменные\n",
    "useful_variables = variables_cnt + variables_dummy + variables_mean + \\\n",
    "                   variables_median + variables_max + ['friends_mail_from_course_pct']\n",
    "\n",
    "# заполняем пропуски нулями\n",
    "df[useful_variables] = df[useful_variables].fillna(0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим выборку на тренировочную и тестовую."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split  # функция для деления \n",
    "\n",
    "# делим в пропорции 80 к 20\n",
    "df_train, df_test = train_test_split(df, test_size = 0.2, random_state=42) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__[0.5] Объясните зачем выборку разбивают на тренировочную и тестовую__ \n",
    "\n",
    "__Ответ:__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Константный прогноз \n",
    "\n",
    "Давайте воспроизведём константный прогноз."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# для удобства запишем в y то, что мы хотим спрогнозировать\n",
    "y_train = df_train['ln_likes_memes'].get_values()\n",
    "y_test = df_test['ln_likes_memes'].get_values()\n",
    "\n",
    "# а в X то, по чему мы это будем делать.\n",
    "X_train = df_train[useful_variables].get_values()\n",
    "X_test = df_test[useful_variables].get_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__[0] Постройте константный прогноз ровно также, как мы делали это на семинаре.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш красивый код \n",
    "\n",
    "y_mean = np.mean(y_train)\n",
    "y_pred_naive = np.ones(len(y_test)) * y_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь давайте посмотрим на тестовой выборке насколько константный прогноз получился хорошим. Будем использовать в качестве метрики качества $MAE$. Подгрузите метрику из `sklearn` и выясните качество работы константного прогноза на тестовой выборке. За вдохновением можно снова обратиться к семинару, но не вздумайте переписывать один в один функцию `print_metrics`. За это буду отнимать баллы.\n",
    "\n",
    "__[0.5] Найдите MAE константного прогноза.__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3478818795857703"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ваш оригинальный код\n",
    "\n",
    "from sklearn import metrics\n",
    "metrics.mean_absolute_error(y_test, y_pred_naive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отлично! Теперь у нас есть с чем сравнить более сложные модели. Давайте займёмся их строительством. \n",
    "\n",
    "## 3. Устойчивая к выбросам регрессия \n",
    "\n",
    "В самом конце семинара мы с вами сделали следущую процедуру: \n",
    "\n",
    "1. Посмотрели какие переменные сильнее всего коррелируют с таргетом, оставили только их\n",
    "2. Оценили устойчивую к выбросам регрессию и выяснили, что она работает лучше константного прогноза\n",
    "\n",
    "Давайте воспроизведём код для её оценки. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male_dummy                        -0.191419\n",
       "mobile_phone_dummy                -0.143059\n",
       "private_prof_dummy                -0.117873\n",
       "home_phone_dummy                  -0.093994\n",
       "twitter_dummy                     -0.081323\n",
       "subscriptions_cnt                 -0.058777\n",
       "can_write_private_message_dummy   -0.048310\n",
       "wall_like_median                  -0.047799\n",
       "wall_comment_median               -0.046382\n",
       "photo_repost_max                  -0.043836\n",
       "dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# сначала посмотрим на чнегативные корреляции\n",
    "corr_neg = df_train[useful_variables].corrwith(df_train['ln_likes_memes']).sort_values()\n",
    "corr_neg[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "friends_from_course_cnt    0.191652\n",
       "videos_cnt                 0.161514\n",
       "wall_text_len_mean         0.159197\n",
       "photo_like_cnt             0.156200\n",
       "pages_cnt                  0.151808\n",
       "wall_text_len_median       0.149763\n",
       "friends_cnt                0.126809\n",
       "photos_cnt                 0.124521\n",
       "instagram_dummy            0.116639\n",
       "wall_text_len_cnt          0.113156\n",
       "dtype: float64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# теперь на позитивные корреляции\n",
    "corr_pos = df_train[useful_variables].corrwith(df_train['ln_likes_memes']).sort_values(ascending=False)\n",
    "corr_pos[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# оставляем в выборке только самые важные переменные \n",
    "best_variables = list(corr_pos[:10].index) + list(corr_neg[:10].index)\n",
    "\n",
    "# Забираем в выборку лучших из лучших \n",
    "X_train = df_train[best_variables].get_values()\n",
    "X_test = df_test[best_variables].get_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовка к оцениванию модели тут заканчивается. Хорошо бы понять в ней каждую строчку кода, потому что сейчас вам надо будет написать что-то похожее самостоятельно. Оцениваем модель!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import HuberRegressor\n",
    "\n",
    "# Объявили модель\n",
    "model_huber = HuberRegressor()\n",
    "\n",
    "# Обучили модель на тренировочной выборке \n",
    "model_huber.fit(X_train, y_train)\n",
    "\n",
    "# Сделали прогнозы на тестовой выборке \n",
    "y_pred_huber_base = model_huber.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__[0.5] Найдите качество модели и убедитесь, что оно лучше константного прогноза.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3622612933778262"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ваша строчка кода\n",
    "metrics.mean_absolute_error(y_test, y_pred_huber_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуйте взять в качетве таргета непрологарифмирование значение лайков. Насколько сильно испортилась модель? Почему? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3702177735836998"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression # подгрузили модель\n",
    "\n",
    "# Объявили модель\n",
    "model_regression = LinearRegression()\n",
    "\n",
    "# Обучили модель на тренировочной выборке \n",
    "model_regression.fit(X_train, y_train)\n",
    "\n",
    "# Сделали прогнозы на тестовой выборке \n",
    "y_pred_regr = model_regression.predict(X_test)\n",
    "\n",
    "metrics.mean_absolute_error(y_test, y_pred_regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## В дз: \n",
    "\n",
    "* __Подозрение:__ оч важны дамми-переменные. Странно, что наличие твиттера так сильно влияет на уменьшение лайков. Посмотрите как часто встречаются в выборке люди с твиттером. Это есть на дамми-гистограмме. Постройте её. Как думаете эта переменная правда важна? Почему? \n",
    "\n",
    "Попробуйте удалить из рассмотрения все дамми-переменные и оценить две регрессии: линейную и хубера. Какое у меоделей качество? Стало ли оно лучше? \n",
    "\n",
    "* Сформулируйте гипотезу о том, какие переменные стоит оставить или выкинуть из рассмотрения. Почему вы так считате? Оцените модель на подходящих на ваш взгляд переменных. Получилось ли улучшить качество прогнозирования? \n",
    "\n",
    "* Обратите внимание, что на картинке с прогнозами очень густой является область с нулевым числом лайков. Может ли быть проблема в том, что в данных есть особая нулевая точка, которую надо рассматривать отдельно и придумывать для неё свою модель? Попробуйте выкинуть из рассмотрения всех, кто поставил нулевое число лайков и построить модель только для положительного их количества. Для моделирования используйте список фичей, который вы придумали в предыдущем пункте. Дополнительно с помощью корреляции с таргетом отберите из этого списка только самые важные фичи."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
