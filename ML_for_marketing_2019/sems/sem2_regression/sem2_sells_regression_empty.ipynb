{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://justaklikaway.files.wordpress.com/2014/05/shut-up-and-take-my-money.jpg\" height=\"400\" width=\"400\"> \n",
    "\n",
    "# <center> ML для маркетинга. <br>  <br> Cюжетная арка 1: продажи </center>\n",
    "\n",
    "В этом семестре мы с вами пройдём через несколько сюжетных арок. Первой такой аркой будут продажи. Им будет посвящена первая серия из семинаров и домашек. \n",
    "\n",
    "\n",
    "#  Эпизод II (атака моделей) \n",
    "\n",
    "В этом эпизоде мы с вами попробуем взять уже предобработанные данные и натравим на них модели. Ох! Ну и жара же сейчас пойдёт."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача \n",
    "\n",
    "В первой части нашего курса мы с вами будем обсуждать такой сюжет, как продажи. Будем стараться их спрогнозировать. Повторите семинары по регрессии из прошлого семестра. Мы будем пользоваться знаниями, которые там получили. Сегодня занимаемся моделированием. В следущий раз занимаемся оценкой бизнес-эффекта от наших моделей. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Как обычно, для начала подгружаем нужные нам пакеты\n",
    "import pandas as pd    # пакет для работы с таблицами \n",
    "import numpy as np     # пакет для работы с матрицами \n",
    "\n",
    "# пакеты для картиночек \n",
    "import matplotlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('ggplot')  # правильный (наиболее красивый) стиль у графиков\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Что уже есть? \n",
    "\n",
    "В прошлый раз мы поговорили о том, зачем надо вдруг кому-то предсказывать продажи и собрали для этих целей датасет по данным walmart. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../sem1_data_prepare/sales_train_v1.tsv', sep='\\t') # подгружаем датасет\n",
    "print('Размерность таблицы:', df.shape)                               # shape показывает его размер\n",
    "df.head()                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Метрики \n",
    "\n",
    "В прошлои семестре мы с вами обсуждали довольно много разных метрик для задачи регрессии. Говорили о разнице между ними и где какую лучше использовать. Помните? Или уже забыли? Если забыли, бегом вспоминать в материалы предыдущего модуля! \n",
    "\n",
    "------------------\n",
    "\n",
    "Мы при решении задачи будем использовать MAE. Давайте подгрузим эту метрику и посчитаем её на игрушечном примере. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# подгружаем метрику mae из sklearn.metrics as mae\n",
    "# ВАША СТРОЧКА КОДА\n",
    "\n",
    "y_test = [1,2,3,4]\n",
    "y_pred = [1,1,1,1]\n",
    "\n",
    "mae(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Тренировочная и тестовая выборки \n",
    "\n",
    "Разбиваем выборку на две части. Кстати говоря, зачем мы это делаем?! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# это то, что мы пытаемся прогнозировать! \n",
    "y = df['ln_future_sales']\n",
    " \n",
    "# то, по чему пытаемся прогнозировать, ln_Weekly_Sales оставили!\n",
    "df = df.drop(['ln_future_sales', 'future_sales', 'Weekly_Sales'], axis=1)\n",
    "X = df.get_values()\n",
    "\n",
    "# Запомним на всякий случй имена всех переменных \n",
    "feature_names = df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем бить по классике. На самом деле, в данных есть временная структура. Мы, в таком разбиении её игнорируем, предполагая, что наблюдения не зависят от времени. Это не совсем правда. Работе с временными рядами в анализе данных посвящена отдельная огромная область. В неё мы не полезем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# СТРОЧКА КОДА С ПОДГРУЗКОЙ train_test_split из sklearn.model_selection\n",
    "\n",
    "# СТРОЧКА С ДРОБЛЕНИЕМ ВЫБОРКИ НА train И test В ПРОПОРЦИИ 70 К 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Наивный прогноз \n",
    "\n",
    "Что такое наивный прогноз небось тоже забыли? Именно его мы построим для наших данных первым делом. Будем говорить, что продажи в любом магазине совпадают со средним значением. Это самый глупый прогноз, который мы можем сделать. С ним мы будем сравнивать прогнозы более сложных моделей. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_mean = np.mean(y_train)                     # посчитали среднее \n",
    "y_pred_naive = np.ones(len(y_test)) * y_mean  # спрогнозировали им продажи\n",
    "y_pred_naive[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# НАЙДИТЕ MAE НАИВНОГО ПРОГНОЗА"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно посмотреть на ошибку не в $\\ln(money)$, а в $money$! Что для этого нужно? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# НАЙДИТЕ MAE НАИВНОГО ПРОГНОЗА В ДЕНЬГАХ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Линейная регрессия \n",
    "\n",
    "Пришло время построить линейную регрессию! Эта модель говорит, что объём продаж формируется в результате суммирования тех характеристик, которыми обладает магазин с какими-то весами\n",
    "\n",
    "$$\n",
    "y = \\beta_0 + \\beta_1 x_1 + ... \\beta_n x_n.\n",
    "$$\n",
    "\n",
    "Например, если мы оценили модель и у нас получилось, что \n",
    "\n",
    "$$ sales = 10000 + 20 \\cdot t,$$\n",
    "\n",
    "то это означает, что средний объём продаж равен 10 тыс. рублей. При этом каждый дополнительный градус температуры на улице, в среднем, при прочих равных, увеличивает объёмы продаж на 20 рублей. \n",
    "\n",
    "Для того, чтобы подобрать коэффициенты обычно минимизируют MSE. Сегодня мы проделаем это на компьютере, в следущий раз проделаем это руками прямо на доске. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression # подгрузили модель\n",
    "\n",
    "# Объявили модель\n",
    "model_reg = LinearRegression()\n",
    "\n",
    "# Обучили модель на тренировочной выборке \n",
    "model_reg.fit(X_train, y_train)\n",
    "\n",
    "# Сделали прогнозы на тестовой выборке \n",
    "y_pred_reg = model_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на ошибку прогноза на тестовой выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# в логарифмах денег\n",
    "mae(y_test, y_pred_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# в деньгах\n",
    "mae(np.exp(y_test), np.exp(y_pred_reg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По сравнению с наивным прогнозом, она довольно сильно упала. Кажется, что за счёт этой модели мы можем каким-то образом сэкономить денег. Правда пока что не очень понятно как именно.  Кстати говоря, для того, чтобы смотреть насколько хорошими, в случае регрессии, получились прогнозы, можно строить такие вот картинки. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_test, y_pred_reg)\n",
    "plt.xlabel('Истинные значения')\n",
    "plt.ylabel('Предсказанные значения')\n",
    "plt.axis('equal')\n",
    "plt.axis('square')\n",
    "plt.xlim([0,plt.xlim()[1]])\n",
    "plt.ylim([0,plt.ylim()[1]])\n",
    "_ = plt.plot([-100, 100], [-100, 100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если все точки на диагонали, значит наша модель строит очень хорошие предсказания. Такую же можно построить и для тренировочной выборки. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_train, model_reg.predict(X_train))\n",
    "plt.xlabel('Истинные значения')\n",
    "plt.ylabel('Предсказанные значения')\n",
    "plt.axis('equal')\n",
    "plt.axis('square')\n",
    "plt.xlim([0,plt.xlim()[1]])\n",
    "plt.ylim([0,plt.ylim()[1]])\n",
    "_ = plt.plot([-100, 100], [-100, 100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если вдруг окажется, что на тренировочных данных прогнозы чётко лежат на диагонали, а на тестовой выборке полный хаос, значит мы переобчуились. Если, конечно, мы не имеем дело со случайным лесом. __Случайный лес не переобучается.__ Или про это вы уже тоже забыли? \n",
    "\n",
    "Посмотрим на то, какие признаки вносят в продажи наибольший вклад. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_reg.coef_  # коэффициенты модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureImportance = pd.DataFrame({\"feature\": feature_names,  \"importance\": model_reg.coef_})\n",
    "featureImportance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureImportance.set_index('feature', inplace=True)\n",
    "featureImportance.sort_values([\"importance\"], ascending=False, inplace=True)\n",
    "featureImportance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureImportance[\"importance\"][:15].plot('bar', figsize=(12,5));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureImportance[\"importance\"][-15:].plot('bar', figsize=(12,5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Почему рождество и чёрная пятница оказались с отрицательными весами? Ответ простой: при предобработке мы сделали ошибку. Мы прогнозируем спрос на завтра. Рождество сегодня. Значит завтра спрос сильно упадёт. Так и просходит в модели. Чтобы дамми, наложенная на рождество оказалась положительной, нам надо было сдвинуть её по времени на единицу, чего мы не сделали. \n",
    "\n",
    "__Мораль:__ если вы видите, что модель себя ведёт странно, возможно, был сделан косяк при предобработке данных. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Кросс-валидация \n",
    "\n",
    "Главная задача обучаемых алгоритмов – их способность обобщаться, то есть хорошо работать на новых данных. Поскольку на новых данных мы сразу не можем проверить качество построенной модели (нам ведь надо для них сделать прогноз, то есть истинных значений целевого признака мы для них не знаем), то надо пожертвовать небольшой порцией данных, чтоб на ней проверить качество модели. Чаще всего это делается одним из 2 способов:\n",
    "\n",
    "\n",
    "* отложенная выборка __(held-out/hold-out set).__ При таком подходе мы оставляем какую-то долю обучающей выборки (как правило от 20% до 40%), обучаем модель на остальных данных (60-80% исходной выборки) и считаем некоторую метрику качества модели. Сейчас мы сделали именно так. У этого подхода есть минусы. Результат работы модели может сильно зависеть от конкретного разбиения. Хочется убить эту зависиомсть. Для этого используют кросс-валидацию. \n",
    "\n",
    "* кросс-валидация __(cross-validation, на русский еще переводят как скользящий или перекрестный контроль).__ Тут самый частый случай – K-fold кросс-валидация\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"https://hsto.org/files/b1d/706/e6c/b1d706e6c9df49c297b6152878a2d03f.png\" height=\"600\" width=\"600\"> \n",
    "\n",
    "\n",
    "Модель обучается $K$ раз на разных подвыборках исходной выборки (белый цвет), а проверяется на одной подвыборке (каждый раз на разной, оранжевый цвет). Получаются $K$ оценок качества модели, которые обычно усредняются, выдавая среднюю оценку качества классификации/регрессии на кросс-валидации. \n",
    "\n",
    "Кросс-валидация дает лучшую, по сравнению с отложенной выборкой, оценку качества модели на новых данных. Но кросс-валидация вычислительно дорогостоящая, если данных много.\n",
    " \n",
    "Кросс-валидация – очень важная техника в машинном обучении, с ее помощью выбираются гиперпараметры моделей, сравниваются модели между собой, оценивается полезность новых признаков в задаче и т.д."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем посмотреть на качество нашей регрессии на кросс-валидации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "mse_val = cross_val_score(model, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "mse_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.sqrt(-1*mse_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Регуляризация\n",
    "\n",
    "Теперь мы умеем оценивать линейную регрессию и смотреть на её качество по кросс-валидации. Пришло время переходить к более сложным моделям. Давайте посмотрим на Lasso-регрессию. Для начала просто оценим её. Потом уже будем смотреть на то, чем она лучше обычной. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso  # подгрузили модель\n",
    "\n",
    "# ОБЪЯВИТЕ МОДЕЛЬ С alpha = 10\n",
    "\n",
    "# ОБУЧИТЕ МОДЕЛЬ МЕТОДОМ fit\n",
    "\n",
    "# ПРОГНОЗЫ НА ТЕСТОВОЙ ВЫБОРКЕ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# КАКОЕ У МОДЕЛИ КАЧЕСТВО"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отлично! Давайте теперь найдём качество модели на кросс-валидации. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# КАКОЕ У МОДЕЛИ КАЧЕСТВО НА КРОСС-ВАЛИДАЦИИ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на коэффициенты модели. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ПОСМОТРИТЕ НА КОЭФФИЦИЕНТЫ МОДЕЛИ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Огромное количество нулей. Как так получилось?  Дело в том, что Lasso-регрессия отличается от обычной специальным штрафом: __регуляризацией.__ В течение всего предыдущего курса мы говорили, что модели часто страдают таким недугом, как переобучение. \n",
    "\n",
    "![](https://cdn-ssl-devio-img.classmethod.jp/wp-content/uploads/2015/05/mlconcepts_image51.png)\n",
    "\n",
    "В случае регрессии это выражается в том, что линия, которую мы проводим, слишком подробно вылизывает точки пространства. На самой правой каритинке именно это и произошло. Для того, чтобы так подробно опутать точки, регрессии надо делать очень резкие повороты. Для резких поворотов ей необходимы большие коэффициенты. \n",
    "\n",
    "Получается, что если мы хотим избежать резких поворотов, и значит, переобучения, нам нужно накладывать на коэффициенты специальные штрафы, которые не дадут им становиться очень-очень большими. Как можно оштрафовать коэффициенты за их размер? Очень просто. Давайте возьмём нашу функцию ошибки, $MSE$, и прибавим к ней дополнительное слагаемое. \n",
    "\n",
    "$$MSE + \\alpha \\cdot \\sum |\\beta|.$$ \n",
    "\n",
    "Теперь мы будем минимизировать не просто квадрат ошибки, а квадрат ошибки плюс сумму модулей коэффициентов. Этот приём не даст нашей модели переобучится. \n",
    "\n",
    "Обратите внимание, что штраф мы вносим с весом $\\alpha$. Если взять $\\alpha = 1000$, то мы говорим, что очень сильно хотим штрафовать коэффициенты за их размер. Если мы берём $\\alpha = 1$, мы говорим, что хотим внести мааааааленький штраф. В нашем случае штраф получился равен $100$. Оказалось, что это довольно много и огромное число коэффициентов занулилось. Качество модели упало. \n",
    "\n",
    "Кроме модулей коэффициентов, можно добавлять штраф из квадратов коэффициентов \n",
    "\n",
    "$$MSE + \\alpha \\cdot \\sum \\beta^2.$$ \n",
    "\n",
    "Такая модель называется redge-регрессией (гребневой регрессией)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возникает вопрос: а надо ли нам вообще в случае наших продаж боятся переобучения и подбирать $\\alpha$? Не очень понятно. Чтобы разобраться обычно пробуют много разных значений $\\alpha$ и ищут такое, чтобы ошибка на кросс-валидации стала поменьше.  Делается это с помощью специального метода: `GridSearch`, поиска по решётке. Такие параметры, как $\\alpha$, которые можно покрутить и посмотреть что изменится, называются __гиперпараметрами модели.__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Решётака для перебора параметра \n",
    "param_grid = {'alpha': [0.001, 0.01, 0.05, 0.1, 0.5, 0.8, 1, 5, 10]}\n",
    "\n",
    "# Объявили модель \n",
    "model_lasso = Lasso() \n",
    "\n",
    "# Объявили перебор, cv=5 это количество фолдов для валидации\n",
    "grid_cv_lasso = GridSearchCV(model_lasso, param_grid, cv = 5, scoring='neg_mean_absolute_error')\n",
    "\n",
    "# обучаем решётку\n",
    "grid_cv_lasso.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перебор работает очень долго. Для каждого `alpha` нам надо учить `cv` моделей. Всего получается в нашей ситуции учится $9 \\cdot 5 = 45$ моделей. Параметров для перебора в моделях бывает много. Обычно поиск по решётке используют в случае $1,2$, ну максимум $3$ параметров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Лучшее значение параметра:', grid_cv_lasso.best_params_)\n",
    "print('Лучшее качество:', grid_cv_lasso.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-1*grid_cv_lasso.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lasso = grid_cv_lasso.best_estimator_\n",
    "\n",
    "# Сделали прогнозы\n",
    "y_pred_lasso = model_lasso.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae(y_test, y_pred_lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучшее `alpha` оказалось очень маленьким. Значит модели не нужна регуляризация. Это хорошая новость. Проблемы начнутся позже, в домашке. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отлично! Давайте попробуем подгрузить другую модель, Ridge. В ней на коэффициенты тоже накладывается штраф, но квадратичный. Попробуйте перебрать его по какой-нибудь решётке и получить оптимальное значение штрафа. Какими у модели оказались коэффициенты? Много ли занулилось? Как думаете, почему так произошло? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ВАШ КОД! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Случайный лес \n",
    "\n",
    "Напоследок давайте попробуем натравить на данные более сложную модель, случайный лес. Вы же ещё не забыли как строятся деревья?  В случае случайного леса они строятся максимально независимо по разным подвыборкам из нашей большой таблички. Каждое дерево даёт нам прогноз, потом мы берём весь лес и усредняем по нему прогнозы. В итоге получается один коллективный прогноз. \n",
    "\n",
    "Ясное дело, что лес будет учиться намного дольше обычной регрессии из-за того, что под капотом леса работает жадный алгоритм. Мы должны попробовать сделать разбиение в каждой вершине дерева в куче разных мест и посмотреть что будет. Помните мы руками на доске учили деревья? Не помните? Уже забыли? Ну и балбесы! Ой, всё. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Объявили лес из 10 деревьев \n",
    "rf = RandomForestRegressor(n_estimators=10)\n",
    "\n",
    "# Обучили лес \n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Сделали по лесу прогнозы \n",
    "y_pred_forest = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Смотрим на прогнозные метрики. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae(y_test, y_pred_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Они же, но в деньгах. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae(np.exp(y_test), np.exp(y_pred_forest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Картинка с прогнозами на тестовой выборке. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_test, y_pred_forest)\n",
    "plt.xlabel('Истинные значения')\n",
    "plt.ylabel('Предсказанные значения')\n",
    "plt.axis('equal')\n",
    "plt.axis('square')\n",
    "plt.xlim([0,plt.xlim()[1]])\n",
    "plt.ylim([0,plt.ylim()[1]])\n",
    "_ = plt.plot([-100, 100], [-100, 100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Она же на тренировочной выборке. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_train, rf.predict(X_train))\n",
    "plt.xlabel('Истинные значения')\n",
    "plt.ylabel('Предсказанные значения')\n",
    "plt.axis('equal')\n",
    "plt.axis('square')\n",
    "plt.xlim([0,plt.xlim()[1]])\n",
    "plt.ylim([0,plt.ylim()[1]])\n",
    "_ = plt.plot([-100, 100], [-100, 100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Внимательный студент завопит в голос, что лес переобучился, потому что он вытянулся вдоль диагонали на тренировочной выборке, а на тестовой не вытянулся! Студент был бы прав, если бы это был __любой другой алгоритм.__ Случайный лес очень хорош тем, что __он не переобучается.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У случайного леса, кстати говоря, тоже куча гиперпараметров. И их тоже все можно перебирать. Правда это займёт ещё больше времени, чем в случае регрессии, так как алгоритм обучает много-много деревьев."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Сохраняем результаты\n",
    "\n",
    "Сохраняем модели на свой компьютер. На следущем семинаре они нам пригодятся. Мы будем более досканально исследовать их с точки зрения безнес-эффекта. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(model_lasso, 'model_lasso.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Лес сохранять не будем, он много весит, но делается это вот так: \n",
    "# joblib.dump(rf, 'model_rf.pkl') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
